#基于yolov5的手势识别
##pc端部署
    yolov5算法是下载官方源码的
    在window端负责使用yolov5识别手势
    把识别结果以usart或socket发出去
    .\weights为模型路径（已经训练好11个手势）
    .\data\ya.yaml
    .\detect为测试代码
##下位机部署
    .\yatime
    在树莓派负责处理结果反馈给舵机，并计算出反应时间
##思路:
    ·整个系统由上位机（PC端）和下位机（树莓派4B）组成，上位机通过本地摄像头、网络摄像头、本地图片采集图像数据代入训练好的YOLOV5模型进行预测处理并每次提取图像中最高置信度的手部姿态，
    将姿态数据通过WIFI（socket模块）或者蓝牙连接发送给下位机，蓝牙通讯系统由PC端外接USB转TTL和蓝牙模块1与树莓派TXRX串口外接蓝牙模块2组成，下位机采用双线程分别对姿态进行更新，更新过程线程锁保存数据，来防止脏数据，另一线程调用第一线程接收的上位机姿态信息，来完成反应力测试逻辑的编写，
    ·反应力测试程序由time模块来计算使用者的反应时间，使用random随机出拳，后打出标记，将下一次识别的手势记录下来与当前的手势进行比较判断输赢，当机器手出拳后使用time记录此时的时间，识别到手势后再次调取时间进行相减计算得出反应时间存进列表里，最后打印整个时间列表、计算出反应总时间与赢的场次和输的场次。
    ·本系统的上位机设计UI界面可进行人机互动调整参数与模型选择，模型有YOLOV5模型与百度API调用，经过多次对比发现百度API成本高且调用速度慢，调用频率有限制，精度不如YOLOV5，YOLOV5为本地模型零成本，调用速度快且频率无限制，因此本系统采用YOLOV5模型。


